# ansible/playbooks/configure-nginx.yml
---
- name: Configure AI Model Endpoints on Multi-Cloud Infrastructure
  hosts: all
  become: yes
  gather_facts: yes
  
  vars:
    model_configs:
      AWS: 
        model_name: "BERT-Large-Uncased"
        model_version: "2.1.0"
        framework: "PyTorch"
        gpu_type: "Tesla-T4"
      Azure:
        model_name: "GPT-2-Medium"
        model_version: "1.5.0"
        framework: "TensorFlow"
        gpu_type: "Tesla-K80"
      GCP:
        model_name: "LLaMA-2-7B"
        model_version: "3.0.1"
        framework: "Transformers"
        gpu_type: "Tesla-T4"
  
  tasks:
    - name: Update package cache (Debian/Ubuntu)
      apt:
        update_cache: yes
      when: ansible_os_family == "Debian"
    
    - name: Update package cache (RedHat/Amazon)
      yum:
        update_cache: yes
      when: ansible_os_family == "RedHat"
    
    - name: Install nginx
      package:
        name: nginx
        state: present
    
    - name: Create AI model directory
      file:
        path: /var/www/ai-endpoint
        state: directory
        owner: www-data
        group: www-data
        mode: '0755'
      when: ansible_os_family == "Debian"
    
    - name: Create AI model directory (RedHat)
      file:
        path: /var/www/ai-endpoint
        state: directory
        owner: nginx
        group: nginx
        mode: '0755'
      when: ansible_os_family == "RedHat"
    
    - name: Deploy AI endpoint HTML page
      template:
        src: ../templates/index.html.j2
        dest: /var/www/ai-endpoint/index.html
        mode: '0644'
      vars:
        model_name: "{{ model_configs[cloud_provider].model_name }}"
        model_version: "{{ model_configs[cloud_provider].model_version }}"
        framework: "{{ model_configs[cloud_provider].framework }}"
        gpu_type: "{{ model_configs[cloud_provider].gpu_type }}"
    
    - name: Create mock API response
      copy:
        content: |
          {
            "status": "healthy",
            "model": "{{ model_configs[cloud_provider].model_name }}",
            "version": "{{ model_configs[cloud_provider].model_version }}",
            "cloud_provider": "{{ cloud_provider }}",
            "inference_time_ms": {{ 20 + (range(1, 50) | random) }},
            "confidence": 0.{{ range(85, 99) | random }},
            "tokens_processed": {{ range(100, 1000) | random }},
            "gpu_utilization": {{ range(60, 95) | random }},
            "timestamp": "{{ ansible_date_time.iso8601 }}"
          }
        dest: /var/www/ai-endpoint/predict.json
        mode: '0644'
        force: yes
    
    - name: Configure nginx site (Debian/Ubuntu)
      copy:
        content: |
          server {
              listen 80 default_server;
              listen [::]:80 default_server;
              server_name _;
              
              root /var/www/ai-endpoint;
              index index.html;
              
              # Main AI endpoint page
              location / {
                  try_files $uri $uri/ =404;
              }
              
              # Mock AI prediction endpoint
              location /v1/models/predict {
                  default_type application/json;
                  try_files /predict.json =404;
                  add_header X-Model-Name "{{ model_configs[cloud_provider].model_name }}";
                  add_header X-Cloud-Provider "{{ cloud_provider }}";
              }
              
              # Health check endpoint
              location /health {
                  default_type application/json;
                  return 200 '{"status":"healthy","provider":"{{ cloud_provider }}"}';
              }
              
              # Metrics endpoint (Prometheus-style)
              location /metrics {
                  default_type text/plain;
                  return 200 'ai_model_requests_total{provider="{{ cloud_provider }}"} {{ range(1000, 5000) | random }}
          ai_model_latency_seconds{provider="{{ cloud_provider }}"} 0.0{{ range(10, 99) | random }}
          ai_model_gpu_utilization{provider="{{ cloud_provider }}"} 0.{{ range(60, 95) | random }}';
              }
              
              # Nginx status for Datadog
              location /nginx_status {
                  stub_status on;
                  access_log off;
                  allow 127.0.0.1;
                  allow ::1;
                  deny all;
              }
          }
        dest: /etc/nginx/sites-available/default
        force: yes
      when: ansible_os_family == "Debian"
      notify: restart nginx
    
    - name: Configure nginx site (RedHat/Amazon)
      copy:
        content: |
          server {
              listen 80 default_server;
              listen [::]:80 default_server;
              server_name _;
              
              root /var/www/ai-endpoint;
              index index.html;
              
              # Main AI endpoint page
              location / {
                  try_files $uri $uri/ =404;
              }
              
              # Mock AI prediction endpoint
              location /v1/models/predict {
                  default_type application/json;
                  try_files /predict.json =404;
                  add_header X-Model-Name "{{ model_configs[cloud_provider].model_name }}";
                  add_header X-Cloud-Provider "{{ cloud_provider }}";
              }
              
              # Health check endpoint
              location /health {
                  default_type application/json;
                  return 200 '{"status":"healthy","provider":"{{ cloud_provider }}"}';
              }
              
              # Metrics endpoint (Prometheus-style)
              location /metrics {
                  default_type text/plain;
                  return 200 'ai_model_requests_total{provider="{{ cloud_provider }}"} {{ range(1000, 5000) | random }}
          ai_model_latency_seconds{provider="{{ cloud_provider }}"} 0.0{{ range(10, 99) | random }}
          ai_model_gpu_utilization{provider="{{ cloud_provider }}"} 0.{{ range(60, 95) | random }}';
              }
              
              # Nginx status for Datadog
              location /nginx_status {
                  stub_status on;
                  access_log off;
                  allow 127.0.0.1;
                  allow ::1;
                  deny all;
              }
          }
        dest: /etc/nginx/conf.d/default.conf
        force: yes
      when: ansible_os_family == "RedHat"
      notify: restart nginx
    
    - name: Ensure nginx is started and enabled
      systemd:
        name: nginx
        state: started
        enabled: yes
    
    # ===== DATADOG AGENT INSTALLATION SECTION =====
    - name: Install and Configure Datadog Agent
      block:
        - name: Download Datadog installation script
          get_url:
            url: https://s3.amazonaws.com/dd-agent/scripts/install_script_agent7.sh
            dest: /tmp/datadog_install.sh
            mode: '0755'
        
        - name: Install Datadog Agent
          shell: |
            DD_API_KEY="{{ datadog_api_key }}" \
            DD_SITE="datadoghq.eu" \
            DD_HOSTNAME="{{ cloud_provider | lower }}-ai-endpoint" \
            bash /tmp/datadog_install.sh
          args:
            creates: /etc/datadog-agent/datadog.yaml
        
        - name: Configure Datadog Agent main config
          copy:
            content: |
              api_key: {{ datadog_api_key }}
              site: datadoghq.eu
              hostname: {{ cloud_provider | lower }}-ai-endpoint
              
              tags:
                - env:production
                - project:cloudguard-trinity
                - cloud:{{ cloud_provider | lower }}
                - model:{{ model_configs[cloud_provider].model_name | lower | replace(' ', '-') }}
                - gpu:{{ model_configs[cloud_provider].gpu_type }}
                - region:{{ ansible_hostname }}
              
              logs_enabled: true
            dest: /etc/datadog-agent/datadog.yaml
            owner: dd-agent
            group: dd-agent
            mode: '0640'
            force: yes
        
        - name: Configure Prometheus scraper for custom metrics
          copy:
            content: |
              init_config:
              
              instances:
                - prometheus_url: http://localhost/metrics
                  namespace: cloudguard
                  metrics:
                    - "*"
                  tags:
                    - cloud:{{ cloud_provider | lower }}
                    - model:{{ model_configs[cloud_provider].model_name | lower | replace(' ', '-') }}
                  timeout: 10
            dest: /etc/datadog-agent/conf.d/prometheus.d/conf.yaml
            owner: dd-agent
            group: dd-agent
            mode: '0644'
            force: yes
        
        - name: Configure nginx monitoring
          copy:
            content: |
              init_config:
              
              instances:
                - nginx_status_url: http://localhost/nginx_status
            dest: /etc/datadog-agent/conf.d/nginx.d/conf.yaml
            owner: dd-agent
            group: dd-agent
            mode: '0644'
            force: yes
        
        - name: Restart Datadog Agent
          systemd:
            name: datadog-agent
            state: restarted
            enabled: yes
            daemon_reload: yes
        
        - name: Wait for agent to start
          pause:
            seconds: 10
        
        - name: Check Datadog Agent status
          command: datadog-agent status
          register: agent_status
          ignore_errors: yes
        
        - name: Display agent status
          debug:
            msg: "Datadog Agent installed and running on {{ cloud_provider }}"
      when: datadog_api_key is defined
    
    # ===== DEPLOYMENT INFO SECTION =====
    - name: Create AI model info file (for verification)
      copy:
        content: |
          ===================================
          CloudGuard AI Platform - Model Deployment
          ===================================
          Cloud Provider: {{ cloud_provider }}
          Model: {{ model_configs[cloud_provider].model_name }}
          Version: {{ model_configs[cloud_provider].model_version }}
          Framework: {{ model_configs[cloud_provider].framework }}
          GPU Type: {{ model_configs[cloud_provider].gpu_type }} (Simulated)
          Endpoint: http://{{ ansible_default_ipv4.address }}/
          API Endpoint: http://{{ ansible_default_ipv4.address }}/v1/models/predict
          Health Check: http://{{ ansible_default_ipv4.address }}/health
          Metrics: http://{{ ansible_default_ipv4.address }}/metrics
          Datadog Agent: {{ 'Installed' if datadog_api_key is defined else 'Not Installed' }}
          ===================================
        dest: /home/{{ ansible_user }}/deployment-info.txt
        mode: '0644'
        force: yes
    
    - name: Display deployment information
      debug:
        msg:
          - "✅ AI Model Endpoint Deployed Successfully!"
          - "Provider: {{ cloud_provider }}"
          - "Model: {{ model_configs[cloud_provider].model_name }}"
          - "URL: http://{{ ansible_default_ipv4.address }}/"
          - "API: http://{{ ansible_default_ipv4.address }}/v1/models/predict"
          - "Datadog Agent: {{ 'Installed and collecting metrics' if datadog_api_key is defined else 'Not installed' }}"
  
  handlers:
    - name: restart nginx
      systemd:
        name: nginx
        state: restarted